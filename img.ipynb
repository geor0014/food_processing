{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is what I used to train the model\n",
    "# Lower I am saving the model so that I can use it in an actual python file \n",
    "# The code for that file can be found here: https://github.com/Team-2-HZ/image-processing/blob/dev-2/python-processing/processImg.py \n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix #lets visualise the model predictions \n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Path('./kaggle/train/') #getting the path of the train dataset\n",
    "train_filepaths = list(train.glob(r'**/*.jpg')) #glob (short for global) is used to return all file paths that match a specific pattern\n",
    "\n",
    "valid = Path('./kaggle/validation/')#for valid dataset\n",
    "valid_filepaths = list(valid.glob(r'**/*.jpg'))\n",
    "\n",
    "test = Path('./kaggle/test/')#for test dataset\n",
    "test_filepaths = list(test.glob(r'**/*.jpg'))\n",
    "\n",
    "user_input = Path('./kaggle/user_input/')#for user input dataset\n",
    "user_input_filepaths = list(user_input.glob(r'**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(filepath): # passing the filepaths of datasets\n",
    "    \n",
    "    labels = [str(filepath[i]).split(\"\\\\\")[-2] #here we are trying to extract the labels for the fruits and veggies by using .split method and\n",
    "              for i in range(len(filepath))] #since names are secound last word we used [-2] to get that particular name\n",
    "    # print(labels)\n",
    "    filepath = pd.Series(filepath, name='FilePath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label') \n",
    "    \n",
    "    df = pd.concat([filepath, labels], axis=1) \n",
    "    df = df.sample(frac=1).reset_index(drop = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = process_img(train_filepaths) \n",
    "valid_df = process_img(valid_filepaths)\n",
    "test_df = process_img(test_filepaths)\n",
    "user_input_df = process_img(user_input_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FilePath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaggle\\train\\lettuce\\Image_1.jpg</td>\n",
       "      <td>lettuce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaggle\\train\\cabbage\\Image_73.jpg</td>\n",
       "      <td>cabbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kaggle\\train\\cabbage\\Image_95.jpg</td>\n",
       "      <td>cabbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kaggle\\train\\spinach\\Image_41.jpg</td>\n",
       "      <td>spinach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaggle\\train\\apple\\Image_49.jpg</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            FilePath    Label\n",
       "0   kaggle\\train\\lettuce\\Image_1.jpg  lettuce\n",
       "1  kaggle\\train\\cabbage\\Image_73.jpg  cabbage\n",
       "2  kaggle\\train\\cabbage\\Image_95.jpg  cabbage\n",
       "3  kaggle\\train\\spinach\\Image_41.jpg  spinach\n",
       "4    kaggle\\train\\apple\\Image_49.jpg    apple"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Training set --\\n')\n",
    "print(f'Number of pictures: {train_df.shape[0]}\\n')\n",
    "print(f'Number of different labels: {len(set(train_df.Label))}\\n')\n",
    "print(f'Labels: {set(train_df.Label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Labels: {set(test_df.Label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = train_df.copy().drop_duplicates(subset=['Label']).reset_index() #we want to see unique images so we are dropping duplicates and since we dont\n",
    "                                                                                    #want to mess up the original df we are coping it using .copy()\n",
    "\n",
    "fig, axes = plt.subplots(6,6, figsize=(10,10),subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(unique_labels.FilePath[i]))\n",
    "    ax.set_title(unique_labels.Label[i], fontsize=12)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2855 validated image filenames belonging to 36 classes.\n",
      "Found 340 validated image filenames belonging to 36 classes.\n",
      "Found 340 validated image filenames belonging to 36 classes.\n",
      "Found 1 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "train_images = data_gen.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col='FilePath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "valid_images = data_gen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col='FilePath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_images = data_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='FilePath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# random images from internet\n",
    "random_images = data_gen.flow_from_dataframe(\n",
    "    dataframe=user_input_df,\n",
    "    x_col='FilePath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model =  tf.keras.applications.MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224,224,3),\n",
    "    pooling='avg',\n",
    ") #this is our base model \n",
    "\n",
    "base_model.trainable = False # we dont want to train the intial weights so we use .trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = base_model.input # this is our input layer which is the base_model's input\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(base_model.output) #here we passed this base_model.output coz on top of our x layer we want the output(bottom) layer of base_model\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(36, activation='softmax')(x)# here we have 36 diff classes so we take 36 as output\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs) # we are passing in our inputs and outputs to our model now\n",
    "\n",
    "model.compile(                                           #lets just compile everthing together \n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "90/90 [==============================] - 165s 2s/step - loss: 1.6926 - accuracy: 0.5524 - val_loss: 0.4590 - val_accuracy: 0.8529\n",
      "Epoch 2/5\n",
      "90/90 [==============================] - 149s 2s/step - loss: 0.5564 - accuracy: 0.8235 - val_loss: 0.2985 - val_accuracy: 0.9118\n",
      "Epoch 3/5\n",
      "90/90 [==============================] - 147s 2s/step - loss: 0.3411 - accuracy: 0.8841 - val_loss: 0.2753 - val_accuracy: 0.9029\n",
      "Epoch 4/5\n",
      "90/90 [==============================] - 148s 2s/step - loss: 0.2233 - accuracy: 0.9296 - val_loss: 0.1740 - val_accuracy: 0.9559\n",
      "Epoch 5/5\n",
      "90/90 [==============================] - 145s 2s/step - loss: 0.1429 - accuracy: 0.9552 - val_loss: 0.1657 - val_accuracy: 0.9441\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(                    #fit the model \n",
    "    train_images,\n",
    "    validation_data=valid_images,\n",
    "    batch_size = 32,\n",
    "    epochs=5,\n",
    "    callbacks=[                   #we are using callbacks for early stopping in case our model doesn't show any improvement after 2 epochs monitoring the monitering the validation loss\n",
    "        tf.keras.callbacks.EarlyStopping(  \n",
    "            monitor='val_loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True #it literally means wat u think (simpleeeeee)\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am loading the model so that I do not need to train it again and again\n",
    "loaded_model = tf.keras.models.load_model('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()  # we are plotting the train and validation accuracy to check on if its overfitting \n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = loaded_model.predict(random_images) #its predicting time , our model will try to predict the prob of the particular class \n",
    "pred = np.argmax(pred, axis=1) # we are seeing the highest prob value and taking the index of it  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 0,\n",
       " 'banana': 1,\n",
       " 'beetroot': 2,\n",
       " 'bell pepper': 3,\n",
       " 'cabbage': 4,\n",
       " 'capsicum': 5,\n",
       " 'carrot': 6,\n",
       " 'cauliflower': 7,\n",
       " 'chilli pepper': 8,\n",
       " 'corn': 9,\n",
       " 'cucumber': 10,\n",
       " 'eggplant': 11,\n",
       " 'garlic': 12,\n",
       " 'ginger': 13,\n",
       " 'grapes': 14,\n",
       " 'jalepeno': 15,\n",
       " 'kiwi': 16,\n",
       " 'lemon': 17,\n",
       " 'lettuce': 18,\n",
       " 'mango': 19,\n",
       " 'onion': 20,\n",
       " 'orange': 21,\n",
       " 'paprika': 22,\n",
       " 'pear': 23,\n",
       " 'peas': 24,\n",
       " 'pineapple': 25,\n",
       " 'pomegranate': 26,\n",
       " 'potato': 27,\n",
       " 'raddish': 28,\n",
       " 'soy beans': 29,\n",
       " 'spinach': 30,\n",
       " 'sweetcorn': 31,\n",
       " 'sweetpotato': 32,\n",
       " 'tomato': 33,\n",
       " 'turnip': 34,\n",
       " 'watermelon': 35}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (train_images.class_indices) #this gives us the labels with indicies to map\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(6,6,figsize=(15,15), subplot_kw={'xticks': [], 'yticks': []}) #will see the actual and predicted labels with images.\n",
    "\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "#     ax.imshow(plt.imread(test_df.FilePath.iloc[i]))\n",
    "#     ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {list(labels.keys())[list(labels.values()).index(pred[i])]}\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pineapple'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the lable of the predicted food \n",
    "predicted_label = list(labels.keys())[pred[0]]\n",
    "predicted_label\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ab1c583b25aec5e4e5697423d16b7a08a79fdc8a7568b28368d332ed7cfe5f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
